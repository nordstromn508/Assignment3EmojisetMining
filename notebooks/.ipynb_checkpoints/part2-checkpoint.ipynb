{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dataset format\n",
    "An event is a list of emojis.\n",
    "\n",
    "A sequence is a list of events.\n",
    "\n",
    "A dataset is a list of sequences.\n",
    "\n",
    "Thus, a dataset is a list of lists of lists of emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example =  [\n",
    "    [[\"a\"], [\"a\", \"b\", \"c\"], [\"a\", \"c\"], [\"c\"]],\n",
    "    [[\"a\"], [\"c\"], [\"b\", \"c\"]],\n",
    "    [[\"a\", \"b\"], [\"d\"], [\"c\"], [\"b\"], [\"c\"]],\n",
    "    [[\"a\"], [\"c\"], [\"b\"], [\"c\"]]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['ðŸ’ƒ', 'ðŸ¼', 'ðŸ¤ª', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸŒž'], ['ðŸ™„', 'ðŸ˜¤', 'ðŸ˜ ', 'âœ‹', 'ðŸŒ©']],\n",
       " [['ðŸ’ƒ', 'ðŸ¼', 'ðŸ¤ª', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸŒž'], ['ðŸ™„', 'ðŸ˜¤', 'ðŸ˜ ', 'âœ‹', 'ðŸŒ©']],\n",
       " [['ðŸ¤ '], ['ðŸ˜Ž']],\n",
       " [['ðŸ·'], ['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ˜Š']],\n",
       " [['ðŸ’ƒ', 'ðŸ¼', 'ðŸ¤ª', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸŒž'], ['ðŸ™„', 'ðŸ˜¤', 'ðŸ˜ ', 'âœ‹', 'ðŸŒ©']]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert emoji data set to the above format\n",
    "data = pd.read_excel('../Emojisets_.xlsx')\n",
    "emojiset = data.iloc[1:, 1]\n",
    "\n",
    "dataset = []\n",
    "for i in range(len(emojiset)):\n",
    "    seq = []\n",
    "    emojiset_split = emojiset.iloc[i][:].split(',')\n",
    "    for combined_emojis in emojiset_split:\n",
    "        event = list(combined_emojis)\n",
    "        seq.append(event)\n",
    "    dataset.append(seq)\n",
    "    \n",
    "dataset[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations\n",
    "### Subsequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is a simple recursive method that checks if subsequence is a subSequence of mainSequence\n",
    "\"\"\"\n",
    "def isSubsequence(mainSequence, subSequence):\n",
    "    subSequenceClone = list(subSequence) # clone the sequence, because we will alter it\n",
    "    return isSubsequenceRecursive(mainSequence, subSequenceClone) #start recursion\n",
    "\n",
    "\"\"\"\n",
    "Function for the recursive call of isSubsequence, not intended for external calls\n",
    "\"\"\"\n",
    "def isSubsequenceRecursive(mainSequence, subSequenceClone, start=0):\n",
    "    # Check if empty: End of recursion, all itemsets have been found\n",
    "    if (not subSequenceClone):\n",
    "        return True\n",
    "    # retrieves element of the subsequence and removes is from subsequence \n",
    "    firstElem = set(subSequenceClone.pop(0))\n",
    "    # Search for the first itemset...\n",
    "    for i in range(start, len(mainSequence)):\n",
    "        if (set(mainSequence[i]).issuperset(firstElem)):\n",
    "            # and recurse\n",
    "            return isSubsequenceRecursive(mainSequence, subSequenceClone, i + 1)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ðŸ’ƒ', 'ðŸ¼', 'ðŸ¤ª', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸŒž'], ['ðŸ™„', 'ðŸ˜¤', 'ðŸ˜ ', 'âœ‹', 'ðŸŒ©']]\n"
     ]
    }
   ],
   "source": [
    "aSequence = dataset[1]\n",
    "print( aSequence )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isSubsequence(aSequence, [[\"ðŸ˜Ž\"], [\"ðŸ™„\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isSubsequence(aSequence, [[\"ðŸ˜Ž\"], [\"ðŸ¤ \", \"ðŸŒž\"], [\"âœ‹\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isSubsequence(aSequence, [[\"ðŸ¤ \", \"ðŸŒž\"], [\"âœ‹\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of an itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Computes the length of the sequence (sum of the length of the contained itemsets)\n",
    "\"\"\"\n",
    "def sequenceLength(sequence):\n",
    "    return sum(len(i) for i in sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ðŸ’ƒ', 'ðŸ¼', 'ðŸ¤ª', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸŒž'], ['ðŸ™„', 'ðŸ˜¤', 'ðŸ˜ ', 'âœ‹', 'ðŸŒ©']]\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print (dataset[0])\n",
    "print (sequenceLength (dataset[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support of a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Computes the support of a sequence in a dataset\n",
    "\"\"\"\n",
    "def countSupport (dataset, candidateSequence):\n",
    "    return sum(1 for seq in dataset if isSubsequence(seq, candidateSequence)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countSupport(dataset, [['ðŸ˜Š']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AprioriAll\n",
    "### 1 . Candidate Generation\n",
    "#### For a single pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generates one candidate of length k from two candidates of length (k-1) as used in the AprioriAll algorithm\n",
    "\"\"\"\n",
    "def generateCandidatesForPair(cand1, cand2):\n",
    "    cand1Clone = copy.deepcopy(cand1)\n",
    "    cand2Clone = copy.deepcopy(cand2)\n",
    "    # drop the leftmost item from cand1:\n",
    "    if (len (cand1[0]) == 1):\n",
    "        cand1Clone.pop(0)\n",
    "    else:\n",
    "        cand1Clone[0] = cand1Clone[0][1:]\n",
    "    # drop the rightmost item from cand2:\n",
    "    if (len (cand2[-1]) == 1):\n",
    "        cand2Clone.pop(-1)\n",
    "    else:\n",
    "        cand2Clone[-1] = cand2Clone[-1][:-1]\n",
    "    \n",
    "    # if the result is not the same, then we dont need to join\n",
    "    if not cand1Clone == cand2Clone:\n",
    "        return []\n",
    "    else:\n",
    "        newCandidate = copy.deepcopy(cand1)\n",
    "        if (len (cand2[-1]) == 1):\n",
    "            newCandidate.append(cand2[-1])\n",
    "        else:\n",
    "            newCandidate [-1].extend(cand2[-1][-1])\n",
    "        return newCandidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ðŸŒž'], ['ðŸ¤ª']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidateA = [[\"ðŸŒž\"]]\n",
    "candidateB = [[\"ðŸ¤ª\"]]\n",
    "generateCandidatesForPair(candidateA, candidateB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ðŸŒž'], ['ðŸ™„', 'ðŸ˜¤'], ['ðŸ¤ª'], ['âœ‹']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidateA = [['ðŸŒž'], ['ðŸ™„', 'ðŸ˜¤'], ['ðŸ¤ª']]\n",
    "candidateC = [['ðŸ™„', 'ðŸ˜¤'], ['ðŸ¤ª'], ['âœ‹']]\n",
    "generateCandidatesForPair(candidateA, candidateC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidateA = [['ðŸŒž'], ['ðŸ™„', 'ðŸ˜¤'], ['ðŸ¤ª']]\n",
    "candidateD = [['ðŸŒž'], ['ðŸ™„', 'ðŸ˜¤'], ['ðŸ¤ª']]\n",
    "generateCandidatesForPair(candidateA, candidateD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For a set of candidates (of the last level):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generates the set of candidates of length k from the set of frequent sequences with length (k-1)\n",
    "\"\"\"\n",
    "def generateCandidates(lastLevelCandidates):\n",
    "    k = sequenceLength(lastLevelCandidates[0]) + 1\n",
    "    if (k == 2):\n",
    "        flatShortCandidates = [item for sublist2 in lastLevelCandidates for sublist1 in sublist2 for item in sublist1]\n",
    "        result = [[[a, b]] for a in flatShortCandidates for b in flatShortCandidates if b > a]\n",
    "        result.extend([[[a], [b]] for a in flatShortCandidates for b in flatShortCandidates])\n",
    "        return result\n",
    "    else:\n",
    "        candidates = []\n",
    "        for i in range(0, len(lastLevelCandidates)):\n",
    "            for j in range(0, len(lastLevelCandidates)):\n",
    "                newCand = generateCandidatesForPair(lastLevelCandidates[i], lastLevelCandidates[j])\n",
    "                if (not newCand == []):\n",
    "                    candidates.append(newCand)\n",
    "        candidates.sort()\n",
    "        return candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example; Lets assume, we know the frequent sequences of level 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lastLevelFrequentPatterns = [\n",
    "    [['ðŸ™„', 'ðŸ˜¤']], \n",
    "    [['ðŸ˜¤', 'âœ‹']], \n",
    "    [['ðŸ™„'], ['ðŸ˜¤']], \n",
    "    [['ðŸ™„'], ['âœ‹']], \n",
    "    [['ðŸ˜¤'], ['âœ‹']],\n",
    "    [['âœ‹'], ['ðŸ˜¤']], \n",
    "    [['âœ‹'], ['âœ‹']],  \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can compute the generate candidates for level 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['âœ‹'], ['âœ‹'], ['âœ‹']],\n",
       " [['âœ‹'], ['âœ‹'], ['ðŸ˜¤']],\n",
       " [['âœ‹'], ['ðŸ˜¤'], ['âœ‹']],\n",
       " [['âœ‹'], ['ðŸ˜¤', 'âœ‹']],\n",
       " [['ðŸ˜¤'], ['âœ‹'], ['âœ‹']],\n",
       " [['ðŸ˜¤'], ['âœ‹'], ['ðŸ˜¤']],\n",
       " [['ðŸ˜¤', 'âœ‹'], ['âœ‹']],\n",
       " [['ðŸ˜¤', 'âœ‹'], ['ðŸ˜¤']],\n",
       " [['ðŸ™„'], ['âœ‹'], ['âœ‹']],\n",
       " [['ðŸ™„'], ['âœ‹'], ['ðŸ˜¤']],\n",
       " [['ðŸ™„'], ['ðŸ˜¤'], ['âœ‹']],\n",
       " [['ðŸ™„'], ['ðŸ˜¤', 'âœ‹']],\n",
       " [['ðŸ™„', 'ðŸ˜¤'], ['âœ‹']],\n",
       " [['ðŸ™„', 'ðŸ˜¤', 'âœ‹']]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newCandidates = generateCandidates(lastLevelFrequentPatterns)\n",
    "newCandidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 . Candidate Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Computes all direct subsequence for a given sequence.\n",
    "A direct subsequence is any sequence that originates from deleting exactly one item from any event in the original sequence.\n",
    "\"\"\"\n",
    "def generateDirectSubsequences(sequence):\n",
    "    result = []\n",
    "    for i, itemset in enumerate(sequence):\n",
    "        if (len(itemset) == 1):\n",
    "            sequenceClone = copy.deepcopy(sequence)\n",
    "            sequenceClone.pop(i)\n",
    "            result.append(sequenceClone)\n",
    "        else:\n",
    "            for j in range(len(itemset)):\n",
    "                sequenceClone = copy.deepcopy(sequence)\n",
    "                sequenceClone[i].pop(j)\n",
    "                result.append(sequenceClone)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prunes the set of candidates generated for length k given all frequent sequence of level (k-1), as done in AprioriAll\n",
    "\"\"\"\n",
    "def pruneCandidates(candidatesLastLevel, candidatesGenerated):\n",
    "    return [cand for cand in candidatesGenerated if all(x in candidatesLastLevel for x in generateDirectSubsequences(cand))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply this on example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['âœ‹'], ['âœ‹'], ['âœ‹']],\n",
       " [['âœ‹'], ['âœ‹'], ['ðŸ˜¤']],\n",
       " [['âœ‹'], ['ðŸ˜¤'], ['âœ‹']],\n",
       " [['âœ‹'], ['ðŸ˜¤', 'âœ‹']],\n",
       " [['ðŸ˜¤'], ['âœ‹'], ['âœ‹']],\n",
       " [['ðŸ˜¤', 'âœ‹'], ['âœ‹']],\n",
       " [['ðŸ™„'], ['âœ‹'], ['âœ‹']],\n",
       " [['ðŸ™„'], ['âœ‹'], ['ðŸ˜¤']],\n",
       " [['ðŸ™„'], ['ðŸ˜¤'], ['âœ‹']],\n",
       " [['ðŸ™„'], ['ðŸ˜¤', 'âœ‹']],\n",
       " [['ðŸ™„', 'ðŸ˜¤'], ['âœ‹']]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidatesPruned = pruneCandidates(lastLevelFrequentPatterns, newCandidates)\n",
    "candidatesPruned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Count Candidates (and filter not frequent ones):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([['ðŸ™„', 'ðŸ˜¤'], ['âœ‹']], 1)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minSupport = 1\n",
    "candidatesCounts = [(i, countSupport(dataset, i)) for i in candidatesPruned]\n",
    "resultLvl = [(i, count) for (i, count) in candidatesCounts if (count >= minSupport)]\n",
    "resultLvl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The AprioriAll algorithm. Computes the frequent sequences in a seqeunce dataset for a given minSupport\n",
    "\n",
    "Args:\n",
    "    dataset: A list of sequences, for which the frequent (sub-)sequences are computed\n",
    "    minSupport: The minimum support that makes a sequence frequent\n",
    "    verbose: If true, additional information on the mining process is printed (i.e., candidates on each level)\n",
    "Returns:\n",
    "    A list of tuples (s, c), where s is a frequent sequence, and c is the count for that sequence\n",
    "\"\"\"\n",
    "def apriori(dataset, minSupport, verbose=False):\n",
    "    global numberOfCountingOperations\n",
    "    numberOfCountingOperations = 0\n",
    "    Overall = []\n",
    "    itemsInDataset = sorted(set ([item for sublist1 in dataset for sublist2 in sublist1 for item in sublist2]))\n",
    "    singleItemSequences = [[[item]] for item in itemsInDataset]\n",
    "    singleItemCounts = [(i, countSupport(dataset, i)) for i in singleItemSequences if countSupport(dataset, i) >= minSupport]\n",
    "    Overall.append(singleItemCounts)\n",
    "    print (\"Result, lvl 1: \" + str(Overall[0]))\n",
    "    k = 1\n",
    "    while (True):\n",
    "        if not Overall [k - 1]:\n",
    "            break\n",
    "        # 1. Candidate generation\n",
    "        candidatesLastLevel = [x[0] for x in Overall[k - 1]]\n",
    "        candidatesGenerated = generateCandidates (candidatesLastLevel)\n",
    "        # 2. Candidate pruning (using a \"containsall\" subsequences)\n",
    "        candidatesPruned = [cand for cand in candidatesGenerated if all(x in candidatesLastLevel for x in generateDirectSubsequences(cand))]\n",
    "        # 3. Candidate checking\n",
    "        candidatesCounts = [(i, countSupport(dataset, i)) for i in candidatesPruned]\n",
    "        resultLvl = [(i, count) for (i, count) in candidatesCounts if (count >= minSupport)]\n",
    "        if verbose:\n",
    "            print (\"Candidates generated, lvl \" + str(k + 1) + \": \" + str(candidatesGenerated))\n",
    "            print (\"Candidates pruned, lvl \" + str(k + 1) + \": \" + str(candidatesPruned))\n",
    "            print (\"Result, lvl \" + str(k + 1) + \": \" + str(resultLvl))\n",
    "        Overall.append(resultLvl)\n",
    "        k = k + 1\n",
    "    # \"flatten\" Overall\n",
    "    Overall = Overall [:-1]\n",
    "    Overall = [item for sublist in Overall for item in sublist]\n",
    "    return Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result, lvl 1: [([['ï¸']], 206), ([['ðŸ¤']], 120), ([['ðŸ¦']], 178), ([['ðŸ”¥']], 197), ([['ðŸ˜']], 101), ([['ðŸ˜Ž']], 1000), ([['ðŸ˜˜']], 110), ([['ðŸ¤—']], 102), ([['ðŸ¤ ']], 1000), ([['ðŸ¥°']], 233)]\n",
      "Candidates generated, lvl 2: [[['ï¸', 'ðŸ¤']], [['ï¸', 'ðŸ¦']], [['ï¸', 'ðŸ”¥']], [['ï¸', 'ðŸ˜']], [['ï¸', 'ðŸ˜Ž']], [['ï¸', 'ðŸ˜˜']], [['ï¸', 'ðŸ¤—']], [['ï¸', 'ðŸ¤ ']], [['ï¸', 'ðŸ¥°']], [['ðŸ¤', 'ðŸ¦']], [['ðŸ¤', 'ðŸ”¥']], [['ðŸ¤', 'ðŸ˜']], [['ðŸ¤', 'ðŸ˜Ž']], [['ðŸ¤', 'ðŸ˜˜']], [['ðŸ¤', 'ðŸ¤—']], [['ðŸ¤', 'ðŸ¤ ']], [['ðŸ¤', 'ðŸ¥°']], [['ðŸ¦', 'ðŸ”¥']], [['ðŸ¦', 'ðŸ˜']], [['ðŸ¦', 'ðŸ˜Ž']], [['ðŸ¦', 'ðŸ˜˜']], [['ðŸ¦', 'ðŸ¤—']], [['ðŸ¦', 'ðŸ¤ ']], [['ðŸ¦', 'ðŸ¥°']], [['ðŸ”¥', 'ðŸ˜']], [['ðŸ”¥', 'ðŸ˜Ž']], [['ðŸ”¥', 'ðŸ˜˜']], [['ðŸ”¥', 'ðŸ¤—']], [['ðŸ”¥', 'ðŸ¤ ']], [['ðŸ”¥', 'ðŸ¥°']], [['ðŸ˜', 'ðŸ˜Ž']], [['ðŸ˜', 'ðŸ˜˜']], [['ðŸ˜', 'ðŸ¤—']], [['ðŸ˜', 'ðŸ¤ ']], [['ðŸ˜', 'ðŸ¥°']], [['ðŸ˜Ž', 'ðŸ˜˜']], [['ðŸ˜Ž', 'ðŸ¤—']], [['ðŸ˜Ž', 'ðŸ¤ ']], [['ðŸ˜Ž', 'ðŸ¥°']], [['ðŸ˜˜', 'ðŸ¤—']], [['ðŸ˜˜', 'ðŸ¤ ']], [['ðŸ˜˜', 'ðŸ¥°']], [['ðŸ¤—', 'ðŸ¤ ']], [['ðŸ¤—', 'ðŸ¥°']], [['ðŸ¤ ', 'ðŸ¥°']], [['ï¸'], ['ï¸']], [['ï¸'], ['ðŸ¤']], [['ï¸'], ['ðŸ¦']], [['ï¸'], ['ðŸ”¥']], [['ï¸'], ['ðŸ˜']], [['ï¸'], ['ðŸ˜Ž']], [['ï¸'], ['ðŸ˜˜']], [['ï¸'], ['ðŸ¤—']], [['ï¸'], ['ðŸ¤ ']], [['ï¸'], ['ðŸ¥°']], [['ðŸ¤'], ['ï¸']], [['ðŸ¤'], ['ðŸ¤']], [['ðŸ¤'], ['ðŸ¦']], [['ðŸ¤'], ['ðŸ”¥']], [['ðŸ¤'], ['ðŸ˜']], [['ðŸ¤'], ['ðŸ˜Ž']], [['ðŸ¤'], ['ðŸ˜˜']], [['ðŸ¤'], ['ðŸ¤—']], [['ðŸ¤'], ['ðŸ¤ ']], [['ðŸ¤'], ['ðŸ¥°']], [['ðŸ¦'], ['ï¸']], [['ðŸ¦'], ['ðŸ¤']], [['ðŸ¦'], ['ðŸ¦']], [['ðŸ¦'], ['ðŸ”¥']], [['ðŸ¦'], ['ðŸ˜']], [['ðŸ¦'], ['ðŸ˜Ž']], [['ðŸ¦'], ['ðŸ˜˜']], [['ðŸ¦'], ['ðŸ¤—']], [['ðŸ¦'], ['ðŸ¤ ']], [['ðŸ¦'], ['ðŸ¥°']], [['ðŸ”¥'], ['ï¸']], [['ðŸ”¥'], ['ðŸ¤']], [['ðŸ”¥'], ['ðŸ¦']], [['ðŸ”¥'], ['ðŸ”¥']], [['ðŸ”¥'], ['ðŸ˜']], [['ðŸ”¥'], ['ðŸ˜Ž']], [['ðŸ”¥'], ['ðŸ˜˜']], [['ðŸ”¥'], ['ðŸ¤—']], [['ðŸ”¥'], ['ðŸ¤ ']], [['ðŸ”¥'], ['ðŸ¥°']], [['ðŸ˜'], ['ï¸']], [['ðŸ˜'], ['ðŸ¤']], [['ðŸ˜'], ['ðŸ¦']], [['ðŸ˜'], ['ðŸ”¥']], [['ðŸ˜'], ['ðŸ˜']], [['ðŸ˜'], ['ðŸ˜Ž']], [['ðŸ˜'], ['ðŸ˜˜']], [['ðŸ˜'], ['ðŸ¤—']], [['ðŸ˜'], ['ðŸ¤ ']], [['ðŸ˜'], ['ðŸ¥°']], [['ðŸ˜Ž'], ['ï¸']], [['ðŸ˜Ž'], ['ðŸ¤']], [['ðŸ˜Ž'], ['ðŸ¦']], [['ðŸ˜Ž'], ['ðŸ”¥']], [['ðŸ˜Ž'], ['ðŸ˜']], [['ðŸ˜Ž'], ['ðŸ˜Ž']], [['ðŸ˜Ž'], ['ðŸ˜˜']], [['ðŸ˜Ž'], ['ðŸ¤—']], [['ðŸ˜Ž'], ['ðŸ¤ ']], [['ðŸ˜Ž'], ['ðŸ¥°']], [['ðŸ˜˜'], ['ï¸']], [['ðŸ˜˜'], ['ðŸ¤']], [['ðŸ˜˜'], ['ðŸ¦']], [['ðŸ˜˜'], ['ðŸ”¥']], [['ðŸ˜˜'], ['ðŸ˜']], [['ðŸ˜˜'], ['ðŸ˜Ž']], [['ðŸ˜˜'], ['ðŸ˜˜']], [['ðŸ˜˜'], ['ðŸ¤—']], [['ðŸ˜˜'], ['ðŸ¤ ']], [['ðŸ˜˜'], ['ðŸ¥°']], [['ðŸ¤—'], ['ï¸']], [['ðŸ¤—'], ['ðŸ¤']], [['ðŸ¤—'], ['ðŸ¦']], [['ðŸ¤—'], ['ðŸ”¥']], [['ðŸ¤—'], ['ðŸ˜']], [['ðŸ¤—'], ['ðŸ˜Ž']], [['ðŸ¤—'], ['ðŸ˜˜']], [['ðŸ¤—'], ['ðŸ¤—']], [['ðŸ¤—'], ['ðŸ¤ ']], [['ðŸ¤—'], ['ðŸ¥°']], [['ðŸ¤ '], ['ï¸']], [['ðŸ¤ '], ['ðŸ¤']], [['ðŸ¤ '], ['ðŸ¦']], [['ðŸ¤ '], ['ðŸ”¥']], [['ðŸ¤ '], ['ðŸ˜']], [['ðŸ¤ '], ['ðŸ˜Ž']], [['ðŸ¤ '], ['ðŸ˜˜']], [['ðŸ¤ '], ['ðŸ¤—']], [['ðŸ¤ '], ['ðŸ¤ ']], [['ðŸ¤ '], ['ðŸ¥°']], [['ðŸ¥°'], ['ï¸']], [['ðŸ¥°'], ['ðŸ¤']], [['ðŸ¥°'], ['ðŸ¦']], [['ðŸ¥°'], ['ðŸ”¥']], [['ðŸ¥°'], ['ðŸ˜']], [['ðŸ¥°'], ['ðŸ˜Ž']], [['ðŸ¥°'], ['ðŸ˜˜']], [['ðŸ¥°'], ['ðŸ¤—']], [['ðŸ¥°'], ['ðŸ¤ ']], [['ðŸ¥°'], ['ðŸ¥°']]]\n",
      "Candidates pruned, lvl 2: [[['ï¸', 'ðŸ¤']], [['ï¸', 'ðŸ¦']], [['ï¸', 'ðŸ”¥']], [['ï¸', 'ðŸ˜']], [['ï¸', 'ðŸ˜Ž']], [['ï¸', 'ðŸ˜˜']], [['ï¸', 'ðŸ¤—']], [['ï¸', 'ðŸ¤ ']], [['ï¸', 'ðŸ¥°']], [['ðŸ¤', 'ðŸ¦']], [['ðŸ¤', 'ðŸ”¥']], [['ðŸ¤', 'ðŸ˜']], [['ðŸ¤', 'ðŸ˜Ž']], [['ðŸ¤', 'ðŸ˜˜']], [['ðŸ¤', 'ðŸ¤—']], [['ðŸ¤', 'ðŸ¤ ']], [['ðŸ¤', 'ðŸ¥°']], [['ðŸ¦', 'ðŸ”¥']], [['ðŸ¦', 'ðŸ˜']], [['ðŸ¦', 'ðŸ˜Ž']], [['ðŸ¦', 'ðŸ˜˜']], [['ðŸ¦', 'ðŸ¤—']], [['ðŸ¦', 'ðŸ¤ ']], [['ðŸ¦', 'ðŸ¥°']], [['ðŸ”¥', 'ðŸ˜']], [['ðŸ”¥', 'ðŸ˜Ž']], [['ðŸ”¥', 'ðŸ˜˜']], [['ðŸ”¥', 'ðŸ¤—']], [['ðŸ”¥', 'ðŸ¤ ']], [['ðŸ”¥', 'ðŸ¥°']], [['ðŸ˜', 'ðŸ˜Ž']], [['ðŸ˜', 'ðŸ˜˜']], [['ðŸ˜', 'ðŸ¤—']], [['ðŸ˜', 'ðŸ¤ ']], [['ðŸ˜', 'ðŸ¥°']], [['ðŸ˜Ž', 'ðŸ˜˜']], [['ðŸ˜Ž', 'ðŸ¤—']], [['ðŸ˜Ž', 'ðŸ¤ ']], [['ðŸ˜Ž', 'ðŸ¥°']], [['ðŸ˜˜', 'ðŸ¤—']], [['ðŸ˜˜', 'ðŸ¤ ']], [['ðŸ˜˜', 'ðŸ¥°']], [['ðŸ¤—', 'ðŸ¤ ']], [['ðŸ¤—', 'ðŸ¥°']], [['ðŸ¤ ', 'ðŸ¥°']], [['ï¸'], ['ï¸']], [['ï¸'], ['ðŸ¤']], [['ï¸'], ['ðŸ¦']], [['ï¸'], ['ðŸ”¥']], [['ï¸'], ['ðŸ˜']], [['ï¸'], ['ðŸ˜Ž']], [['ï¸'], ['ðŸ˜˜']], [['ï¸'], ['ðŸ¤—']], [['ï¸'], ['ðŸ¤ ']], [['ï¸'], ['ðŸ¥°']], [['ðŸ¤'], ['ï¸']], [['ðŸ¤'], ['ðŸ¤']], [['ðŸ¤'], ['ðŸ¦']], [['ðŸ¤'], ['ðŸ”¥']], [['ðŸ¤'], ['ðŸ˜']], [['ðŸ¤'], ['ðŸ˜Ž']], [['ðŸ¤'], ['ðŸ˜˜']], [['ðŸ¤'], ['ðŸ¤—']], [['ðŸ¤'], ['ðŸ¤ ']], [['ðŸ¤'], ['ðŸ¥°']], [['ðŸ¦'], ['ï¸']], [['ðŸ¦'], ['ðŸ¤']], [['ðŸ¦'], ['ðŸ¦']], [['ðŸ¦'], ['ðŸ”¥']], [['ðŸ¦'], ['ðŸ˜']], [['ðŸ¦'], ['ðŸ˜Ž']], [['ðŸ¦'], ['ðŸ˜˜']], [['ðŸ¦'], ['ðŸ¤—']], [['ðŸ¦'], ['ðŸ¤ ']], [['ðŸ¦'], ['ðŸ¥°']], [['ðŸ”¥'], ['ï¸']], [['ðŸ”¥'], ['ðŸ¤']], [['ðŸ”¥'], ['ðŸ¦']], [['ðŸ”¥'], ['ðŸ”¥']], [['ðŸ”¥'], ['ðŸ˜']], [['ðŸ”¥'], ['ðŸ˜Ž']], [['ðŸ”¥'], ['ðŸ˜˜']], [['ðŸ”¥'], ['ðŸ¤—']], [['ðŸ”¥'], ['ðŸ¤ ']], [['ðŸ”¥'], ['ðŸ¥°']], [['ðŸ˜'], ['ï¸']], [['ðŸ˜'], ['ðŸ¤']], [['ðŸ˜'], ['ðŸ¦']], [['ðŸ˜'], ['ðŸ”¥']], [['ðŸ˜'], ['ðŸ˜']], [['ðŸ˜'], ['ðŸ˜Ž']], [['ðŸ˜'], ['ðŸ˜˜']], [['ðŸ˜'], ['ðŸ¤—']], [['ðŸ˜'], ['ðŸ¤ ']], [['ðŸ˜'], ['ðŸ¥°']], [['ðŸ˜Ž'], ['ï¸']], [['ðŸ˜Ž'], ['ðŸ¤']], [['ðŸ˜Ž'], ['ðŸ¦']], [['ðŸ˜Ž'], ['ðŸ”¥']], [['ðŸ˜Ž'], ['ðŸ˜']], [['ðŸ˜Ž'], ['ðŸ˜Ž']], [['ðŸ˜Ž'], ['ðŸ˜˜']], [['ðŸ˜Ž'], ['ðŸ¤—']], [['ðŸ˜Ž'], ['ðŸ¤ ']], [['ðŸ˜Ž'], ['ðŸ¥°']], [['ðŸ˜˜'], ['ï¸']], [['ðŸ˜˜'], ['ðŸ¤']], [['ðŸ˜˜'], ['ðŸ¦']], [['ðŸ˜˜'], ['ðŸ”¥']], [['ðŸ˜˜'], ['ðŸ˜']], [['ðŸ˜˜'], ['ðŸ˜Ž']], [['ðŸ˜˜'], ['ðŸ˜˜']], [['ðŸ˜˜'], ['ðŸ¤—']], [['ðŸ˜˜'], ['ðŸ¤ ']], [['ðŸ˜˜'], ['ðŸ¥°']], [['ðŸ¤—'], ['ï¸']], [['ðŸ¤—'], ['ðŸ¤']], [['ðŸ¤—'], ['ðŸ¦']], [['ðŸ¤—'], ['ðŸ”¥']], [['ðŸ¤—'], ['ðŸ˜']], [['ðŸ¤—'], ['ðŸ˜Ž']], [['ðŸ¤—'], ['ðŸ˜˜']], [['ðŸ¤—'], ['ðŸ¤—']], [['ðŸ¤—'], ['ðŸ¤ ']], [['ðŸ¤—'], ['ðŸ¥°']], [['ðŸ¤ '], ['ï¸']], [['ðŸ¤ '], ['ðŸ¤']], [['ðŸ¤ '], ['ðŸ¦']], [['ðŸ¤ '], ['ðŸ”¥']], [['ðŸ¤ '], ['ðŸ˜']], [['ðŸ¤ '], ['ðŸ˜Ž']], [['ðŸ¤ '], ['ðŸ˜˜']], [['ðŸ¤ '], ['ðŸ¤—']], [['ðŸ¤ '], ['ðŸ¤ ']], [['ðŸ¤ '], ['ðŸ¥°']], [['ðŸ¥°'], ['ï¸']], [['ðŸ¥°'], ['ðŸ¤']], [['ðŸ¥°'], ['ðŸ¦']], [['ðŸ¥°'], ['ðŸ”¥']], [['ðŸ¥°'], ['ðŸ˜']], [['ðŸ¥°'], ['ðŸ˜Ž']], [['ðŸ¥°'], ['ðŸ˜˜']], [['ðŸ¥°'], ['ðŸ¤—']], [['ðŸ¥°'], ['ðŸ¤ ']], [['ðŸ¥°'], ['ðŸ¥°']]]\n",
      "Result, lvl 2: [([['ï¸', 'ðŸ˜Ž']], 128), ([['ðŸ¤', 'ðŸ¦']], 108), ([['ðŸ¤', 'ðŸ˜Ž']], 120), ([['ðŸ¤', 'ðŸ¤ ']], 120), ([['ðŸ¤', 'ðŸ¥°']], 106), ([['ðŸ¦', 'ðŸ”¥']], 131), ([['ðŸ¦', 'ðŸ˜Ž']], 178), ([['ðŸ¦', 'ðŸ¤ ']], 178), ([['ðŸ¦', 'ðŸ¥°']], 164), ([['ðŸ”¥', 'ðŸ˜Ž']], 163), ([['ðŸ”¥', 'ðŸ¤ ']], 187), ([['ðŸ”¥', 'ðŸ¥°']], 135), ([['ðŸ˜Ž', 'ðŸ¤ ']], 645), ([['ðŸ˜Ž', 'ðŸ¥°']], 211), ([['ðŸ¤ ', 'ðŸ¥°']], 213), ([['ðŸ˜Ž'], ['ðŸ¤ ']], 168), ([['ðŸ¤ '], ['ðŸ˜Ž']], 230)]\n",
      "Candidates generated, lvl 3: [[['ï¸', 'ðŸ˜Ž'], ['ðŸ¤ ']], [['ï¸', 'ðŸ˜Ž', 'ðŸ¤ ']], [['ï¸', 'ðŸ˜Ž', 'ðŸ¥°']], [['ðŸ¤', 'ðŸ¦', 'ðŸ”¥']], [['ðŸ¤', 'ðŸ¦', 'ðŸ˜Ž']], [['ðŸ¤', 'ðŸ¦', 'ðŸ¤ ']], [['ðŸ¤', 'ðŸ¦', 'ðŸ¥°']], [['ðŸ¤', 'ðŸ˜Ž'], ['ðŸ¤ ']], [['ðŸ¤', 'ðŸ˜Ž', 'ðŸ¤ ']], [['ðŸ¤', 'ðŸ˜Ž', 'ðŸ¥°']], [['ðŸ¤', 'ðŸ¤ '], ['ðŸ˜Ž']], [['ðŸ¤', 'ðŸ¤ ', 'ðŸ¥°']], [['ðŸ¦', 'ðŸ”¥', 'ðŸ˜Ž']], [['ðŸ¦', 'ðŸ”¥', 'ðŸ¤ ']], [['ðŸ¦', 'ðŸ”¥', 'ðŸ¥°']], [['ðŸ¦', 'ðŸ˜Ž'], ['ðŸ¤ ']], [['ðŸ¦', 'ðŸ˜Ž', 'ðŸ¤ ']], [['ðŸ¦', 'ðŸ˜Ž', 'ðŸ¥°']], [['ðŸ¦', 'ðŸ¤ '], ['ðŸ˜Ž']], [['ðŸ¦', 'ðŸ¤ ', 'ðŸ¥°']], [['ðŸ”¥', 'ðŸ˜Ž'], ['ðŸ¤ ']], [['ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¤ ']], [['ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¥°']], [['ðŸ”¥', 'ðŸ¤ '], ['ðŸ˜Ž']], [['ðŸ”¥', 'ðŸ¤ ', 'ðŸ¥°']], [['ðŸ˜Ž'], ['ðŸ¤ '], ['ðŸ˜Ž']], [['ðŸ˜Ž'], ['ðŸ¤ ', 'ðŸ¥°']], [['ðŸ˜Ž', 'ðŸ¤ '], ['ðŸ˜Ž']], [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']], [['ðŸ¤ '], ['ðŸ˜Ž'], ['ðŸ¤ ']], [['ðŸ¤ '], ['ðŸ˜Ž', 'ðŸ¤ ']], [['ðŸ¤ '], ['ðŸ˜Ž', 'ðŸ¥°']]]\n",
      "Candidates pruned, lvl 3: [[['ðŸ¤', 'ðŸ¦', 'ðŸ˜Ž']], [['ðŸ¤', 'ðŸ¦', 'ðŸ¤ ']], [['ðŸ¤', 'ðŸ¦', 'ðŸ¥°']], [['ðŸ¤', 'ðŸ˜Ž', 'ðŸ¤ ']], [['ðŸ¤', 'ðŸ˜Ž', 'ðŸ¥°']], [['ðŸ¤', 'ðŸ¤ ', 'ðŸ¥°']], [['ðŸ¦', 'ðŸ”¥', 'ðŸ˜Ž']], [['ðŸ¦', 'ðŸ”¥', 'ðŸ¤ ']], [['ðŸ¦', 'ðŸ”¥', 'ðŸ¥°']], [['ðŸ¦', 'ðŸ˜Ž', 'ðŸ¤ ']], [['ðŸ¦', 'ðŸ˜Ž', 'ðŸ¥°']], [['ðŸ¦', 'ðŸ¤ ', 'ðŸ¥°']], [['ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¤ ']], [['ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¥°']], [['ðŸ”¥', 'ðŸ¤ ', 'ðŸ¥°']], [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']]]\n",
      "Result, lvl 3: [([['ðŸ¤', 'ðŸ¦', 'ðŸ˜Ž']], 108), ([['ðŸ¤', 'ðŸ¦', 'ðŸ¤ ']], 108), ([['ðŸ¤', 'ðŸ˜Ž', 'ðŸ¤ ']], 120), ([['ðŸ¤', 'ðŸ˜Ž', 'ðŸ¥°']], 106), ([['ðŸ¤', 'ðŸ¤ ', 'ðŸ¥°']], 106), ([['ðŸ¦', 'ðŸ”¥', 'ðŸ˜Ž']], 131), ([['ðŸ¦', 'ðŸ”¥', 'ðŸ¤ ']], 131), ([['ðŸ¦', 'ðŸ”¥', 'ðŸ¥°']], 117), ([['ðŸ¦', 'ðŸ˜Ž', 'ðŸ¤ ']], 178), ([['ðŸ¦', 'ðŸ˜Ž', 'ðŸ¥°']], 164), ([['ðŸ¦', 'ðŸ¤ ', 'ðŸ¥°']], 164), ([['ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¤ ']], 161), ([['ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¥°']], 135), ([['ðŸ”¥', 'ðŸ¤ ', 'ðŸ¥°']], 135), ([['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']], 209)]\n",
      "Candidates generated, lvl 4: [[['ðŸ¤', 'ðŸ¦', 'ðŸ˜Ž', 'ðŸ¤ ']], [['ðŸ¤', 'ðŸ¦', 'ðŸ˜Ž', 'ðŸ¥°']], [['ðŸ¤', 'ðŸ¦', 'ðŸ¤ ', 'ðŸ¥°']], [['ðŸ¤', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']], [['ðŸ¦', 'ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¤ ']], [['ðŸ¦', 'ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¥°']], [['ðŸ¦', 'ðŸ”¥', 'ðŸ¤ ', 'ðŸ¥°']], [['ðŸ¦', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']], [['ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']]]\n",
      "Candidates pruned, lvl 4: [[['ðŸ¤', 'ðŸ¦', 'ðŸ˜Ž', 'ðŸ¤ ']], [['ðŸ¤', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']], [['ðŸ¦', 'ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¤ ']], [['ðŸ¦', 'ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¥°']], [['ðŸ¦', 'ðŸ”¥', 'ðŸ¤ ', 'ðŸ¥°']], [['ðŸ¦', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']], [['ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']]]\n",
      "Result, lvl 4: [([['ðŸ¤', 'ðŸ¦', 'ðŸ˜Ž', 'ðŸ¤ ']], 108), ([['ðŸ¤', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']], 106), ([['ðŸ¦', 'ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¤ ']], 131), ([['ðŸ¦', 'ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¥°']], 117), ([['ðŸ¦', 'ðŸ”¥', 'ðŸ¤ ', 'ðŸ¥°']], 117), ([['ðŸ¦', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']], 164), ([['ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']], 135)]\n",
      "Candidates generated, lvl 5: [[['ðŸ¤', 'ðŸ¦', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']], [['ðŸ¦', 'ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']]]\n",
      "Candidates pruned, lvl 5: [[['ðŸ¦', 'ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']]]\n",
      "Result, lvl 5: [([['ðŸ¦', 'ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']], 117)]\n",
      "Candidates generated, lvl 6: []\n",
      "Candidates pruned, lvl 6: []\n",
      "Result, lvl 6: []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[([['ï¸']], 206),\n",
       " ([['ðŸ¤']], 120),\n",
       " ([['ðŸ¦']], 178),\n",
       " ([['ðŸ”¥']], 197),\n",
       " ([['ðŸ˜']], 101),\n",
       " ([['ðŸ˜Ž']], 1000),\n",
       " ([['ðŸ˜˜']], 110),\n",
       " ([['ðŸ¤—']], 102),\n",
       " ([['ðŸ¤ ']], 1000),\n",
       " ([['ðŸ¥°']], 233),\n",
       " ([['ï¸', 'ðŸ˜Ž']], 128),\n",
       " ([['ðŸ¤', 'ðŸ¦']], 108),\n",
       " ([['ðŸ¤', 'ðŸ˜Ž']], 120),\n",
       " ([['ðŸ¤', 'ðŸ¤ ']], 120),\n",
       " ([['ðŸ¤', 'ðŸ¥°']], 106),\n",
       " ([['ðŸ¦', 'ðŸ”¥']], 131),\n",
       " ([['ðŸ¦', 'ðŸ˜Ž']], 178),\n",
       " ([['ðŸ¦', 'ðŸ¤ ']], 178),\n",
       " ([['ðŸ¦', 'ðŸ¥°']], 164),\n",
       " ([['ðŸ”¥', 'ðŸ˜Ž']], 163),\n",
       " ([['ðŸ”¥', 'ðŸ¤ ']], 187),\n",
       " ([['ðŸ”¥', 'ðŸ¥°']], 135),\n",
       " ([['ðŸ˜Ž', 'ðŸ¤ ']], 645),\n",
       " ([['ðŸ˜Ž', 'ðŸ¥°']], 211),\n",
       " ([['ðŸ¤ ', 'ðŸ¥°']], 213),\n",
       " ([['ðŸ˜Ž'], ['ðŸ¤ ']], 168),\n",
       " ([['ðŸ¤ '], ['ðŸ˜Ž']], 230),\n",
       " ([['ðŸ¤', 'ðŸ¦', 'ðŸ˜Ž']], 108),\n",
       " ([['ðŸ¤', 'ðŸ¦', 'ðŸ¤ ']], 108),\n",
       " ([['ðŸ¤', 'ðŸ˜Ž', 'ðŸ¤ ']], 120),\n",
       " ([['ðŸ¤', 'ðŸ˜Ž', 'ðŸ¥°']], 106),\n",
       " ([['ðŸ¤', 'ðŸ¤ ', 'ðŸ¥°']], 106),\n",
       " ([['ðŸ¦', 'ðŸ”¥', 'ðŸ˜Ž']], 131),\n",
       " ([['ðŸ¦', 'ðŸ”¥', 'ðŸ¤ ']], 131),\n",
       " ([['ðŸ¦', 'ðŸ”¥', 'ðŸ¥°']], 117),\n",
       " ([['ðŸ¦', 'ðŸ˜Ž', 'ðŸ¤ ']], 178),\n",
       " ([['ðŸ¦', 'ðŸ˜Ž', 'ðŸ¥°']], 164),\n",
       " ([['ðŸ¦', 'ðŸ¤ ', 'ðŸ¥°']], 164),\n",
       " ([['ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¤ ']], 161),\n",
       " ([['ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¥°']], 135),\n",
       " ([['ðŸ”¥', 'ðŸ¤ ', 'ðŸ¥°']], 135),\n",
       " ([['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']], 209),\n",
       " ([['ðŸ¤', 'ðŸ¦', 'ðŸ˜Ž', 'ðŸ¤ ']], 108),\n",
       " ([['ðŸ¤', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']], 106),\n",
       " ([['ðŸ¦', 'ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¤ ']], 131),\n",
       " ([['ðŸ¦', 'ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¥°']], 117),\n",
       " ([['ðŸ¦', 'ðŸ”¥', 'ðŸ¤ ', 'ðŸ¥°']], 117),\n",
       " ([['ðŸ¦', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']], 164),\n",
       " ([['ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']], 135),\n",
       " ([['ðŸ¦', 'ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']], 117)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriori(dataset, 100, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PrefixSpan\n",
    "\n",
    "### Project a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Projects a sequence according to a given prefix, as done in PrefixSpan\n",
    "\n",
    "Args:\n",
    "    sequence: the sequence the projection is built from\n",
    "    prefix: the prefix that is searched for in the sequence\n",
    "    newEvent: if set to True, the first itemset is ignored\n",
    "Returns:\n",
    "    If the sequence does not contain the prefix, then None.\n",
    "    Otherwise, a new sequence starting from the position of the prefix, including the itemset that includes the prefix\n",
    "\"\"\"\n",
    "def projectSequence(sequence, prefix, newEvent):\n",
    "    result = None\n",
    "    for i, itemset in enumerate(sequence):\n",
    "        if result is None:\n",
    "            if (not newEvent) or i > 0:\n",
    "                if (all(x in itemset for x in prefix)):\n",
    "                    result = [list(itemset)]\n",
    "        else:\n",
    "            result.append(copy.copy(itemset))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ðŸ˜Ž', 'ðŸ¤ '], ['ðŸ¦', 'ðŸ¤ '], ['ðŸ¤ ']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = [[\"ðŸ¦\"], [\"ðŸ˜Ž\", \"ðŸ¤ \"], [\"ðŸ¦\", \"ðŸ¤ \"], [\"ðŸ¤ \"]]\n",
    "projectSequence(seq, [\"ðŸ˜Ž\"], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ðŸ¦', 'ðŸ¤ '], ['ðŸ¤ ']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projectSequence(seq, [\"ðŸ¦\", \"ðŸ¤ \"], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ðŸ¦'], ['ðŸ˜Ž', 'ðŸ¤ '], ['ðŸ¦', 'ðŸ¤ '], ['ðŸ¤ ']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projectSequence(seq, [\"ðŸ¦\"], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ðŸ¦', 'ðŸ¤ '], ['ðŸ¤ ']]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projectSequence(seq, [\"ðŸ¦\"], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Projects a dataset according to a given prefix, as done in PrefixSpan\n",
    "\n",
    "Args:\n",
    "    dataset: the dataset the projection is built from\n",
    "    prefix: the prefix that is searched for in the sequence\n",
    "    newEvent: if set to True, the first itemset is ignored\n",
    "Returns:\n",
    "    A (potentially empty) list of sequences\n",
    "\"\"\"\n",
    "def projectDatabase(dataset, prefix, newEvent):\n",
    "    projectedDB = []\n",
    "    for sequence in dataset:\n",
    "        seqProjected = projectSequence(sequence, prefix, newEvent)\n",
    "        if not seqProjected is None:\n",
    "            projectedDB.append(seqProjected)\n",
    "    return projectedDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤']],\n",
       " [['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°', 'ðŸ¦', 'ðŸ¤', 'ðŸ”¥']]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projectDatabase(dataset, [\"ðŸ¦\"], False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The main algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some more utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generates a list of all items that are contained in a dataset\n",
    "\"\"\"\n",
    "def generateItems(dataset):\n",
    "    return sorted(set ([item for sublist1 in dataset for sublist2 in sublist1 for item in sublist2]))\n",
    "\n",
    "\"\"\"\n",
    "Computes a defaultdict that maps each item in the dataset to its support\n",
    "\"\"\"\n",
    "def generateItemSupports(dataset, ignoreFirstEvent=False, prefix=[]):\n",
    "    result = defaultdict(int)\n",
    "    for sequence in dataset:\n",
    "        if ignoreFirstEvent:\n",
    "            sequence = sequence[1:]\n",
    "        cooccurringItems = set()\n",
    "        for itemset in sequence:\n",
    "            if all(x in itemset for x in prefix):\n",
    "                for item in itemset:\n",
    "                    if not item in prefix:\n",
    "                        cooccurringItems.add(item)\n",
    "        for item in cooccurringItems:\n",
    "            result [item] += 1\n",
    "    return sorted(result.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, the algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The PrefixSpan algorithm. Computes the frequent sequences in a seqeunce dataset for a given minSupport\n",
    "\n",
    "Args:\n",
    "    dataset: A list of sequences, for which the frequent (sub-)sequences are computed\n",
    "    minSupport: The minimum support that makes a sequence frequent\n",
    "Returns:\n",
    "    A list of tuples (s, c), where s is a frequent sequence, and c is the count for that sequence\n",
    "\"\"\"\n",
    "def prefixSpan(dataset, minSupport):\n",
    "    result = []\n",
    "    itemCounts = generateItemSupports(dataset)\n",
    "    for item, count in itemCounts:\n",
    "        if count >= minSupport:\n",
    "            newPrefix = [[item]]\n",
    "            result.append((newPrefix, count))\n",
    "            result.extend(prefixSpanInternal(projectDatabase(dataset, [item], False), minSupport, newPrefix))\n",
    "    return result\n",
    "\n",
    "def prefixSpanInternal(dataset, minSupport, prevPrefixes=[]):\n",
    "    result = []\n",
    "    \n",
    "    # Add a new item to the last element (==same time)\n",
    "    itemCountSameEvent = generateItemSupports(dataset, False, prefix=prevPrefixes[-1])\n",
    "    for item, count in itemCountSameEvent:\n",
    "        if (count >= minSupport) and item > prevPrefixes[-1][-1]:\n",
    "            newPrefix = copy.deepcopy(prevPrefixes)\n",
    "            newPrefix[-1].append(item)\n",
    "            result.append((newPrefix, count))\n",
    "            result.extend(prefixSpanInternal(projectDatabase(dataset, newPrefix[-1], False), minSupport, newPrefix))\n",
    "        \n",
    "    # Add a new event to the prefix\n",
    "    itemCountSubsequentEvents = generateItemSupports(dataset, True)\n",
    "    for item, count in itemCountSubsequentEvents:\n",
    "        if count >= minSupport:\n",
    "            newPrefix = copy.deepcopy(prevPrefixes)\n",
    "            newPrefix.append([item])\n",
    "            result.append((newPrefix, count))\n",
    "            result.extend(prefixSpanInternal(projectDatabase(dataset, [item], True), minSupport, newPrefix))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([['ï¸']], 206),\n",
       " ([['ï¸', 'ðŸ˜Ž']], 128),\n",
       " ([['ðŸ¤']], 120),\n",
       " ([['ðŸ¤', 'ðŸ¦']], 108),\n",
       " ([['ðŸ¤', 'ðŸ¦', 'ðŸ˜Ž']], 108),\n",
       " ([['ðŸ¤', 'ðŸ¦', 'ðŸ˜Ž', 'ðŸ¤ ']], 108),\n",
       " ([['ðŸ¤', 'ðŸ¦', 'ðŸ¤ ']], 108),\n",
       " ([['ðŸ¤', 'ðŸ˜Ž']], 120),\n",
       " ([['ðŸ¤', 'ðŸ˜Ž', 'ðŸ¤ ']], 120),\n",
       " ([['ðŸ¤', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']], 106),\n",
       " ([['ðŸ¤', 'ðŸ˜Ž', 'ðŸ¥°']], 106),\n",
       " ([['ðŸ¤', 'ðŸ¤ ']], 120),\n",
       " ([['ðŸ¤', 'ðŸ¤ ', 'ðŸ¥°']], 106),\n",
       " ([['ðŸ¤', 'ðŸ¥°']], 106),\n",
       " ([['ðŸ¦']], 178),\n",
       " ([['ðŸ¦', 'ðŸ”¥']], 131),\n",
       " ([['ðŸ¦', 'ðŸ”¥', 'ðŸ˜Ž']], 131),\n",
       " ([['ðŸ¦', 'ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¤ ']], 131),\n",
       " ([['ðŸ¦', 'ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']], 117),\n",
       " ([['ðŸ¦', 'ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¥°']], 117),\n",
       " ([['ðŸ¦', 'ðŸ”¥', 'ðŸ¤ ']], 131),\n",
       " ([['ðŸ¦', 'ðŸ”¥', 'ðŸ¤ ', 'ðŸ¥°']], 117),\n",
       " ([['ðŸ¦', 'ðŸ”¥', 'ðŸ¥°']], 117),\n",
       " ([['ðŸ¦', 'ðŸ˜Ž']], 178),\n",
       " ([['ðŸ¦', 'ðŸ˜Ž', 'ðŸ¤ ']], 178),\n",
       " ([['ðŸ¦', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']], 164),\n",
       " ([['ðŸ¦', 'ðŸ˜Ž', 'ðŸ¥°']], 164),\n",
       " ([['ðŸ¦', 'ðŸ¤ ']], 178),\n",
       " ([['ðŸ¦', 'ðŸ¤ ', 'ðŸ¥°']], 164),\n",
       " ([['ðŸ¦', 'ðŸ¥°']], 164),\n",
       " ([['ðŸ”¥']], 197),\n",
       " ([['ðŸ”¥', 'ðŸ˜Ž']], 163),\n",
       " ([['ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¤ ']], 161),\n",
       " ([['ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']], 135),\n",
       " ([['ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¥°']], 135),\n",
       " ([['ðŸ”¥', 'ðŸ¤ ']], 187),\n",
       " ([['ðŸ”¥', 'ðŸ¤ ', 'ðŸ¥°']], 135),\n",
       " ([['ðŸ”¥', 'ðŸ¥°']], 135),\n",
       " ([['ðŸ˜']], 101),\n",
       " ([['ðŸ˜Ž']], 1000),\n",
       " ([['ðŸ˜Ž', 'ðŸ¤ ']], 645),\n",
       " ([['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']], 209),\n",
       " ([['ðŸ˜Ž', 'ðŸ¥°']], 211),\n",
       " ([['ðŸ˜Ž'], ['ðŸ¤ ']], 168),\n",
       " ([['ðŸ˜˜']], 110),\n",
       " ([['ðŸ¤—']], 102),\n",
       " ([['ðŸ¤ ']], 1000),\n",
       " ([['ðŸ¤ ', 'ðŸ¥°']], 213),\n",
       " ([['ðŸ¤ '], ['ðŸ˜Ž']], 230),\n",
       " ([['ðŸ¥°']], 233)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefixSpan(dataset, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter for closed and maximal patterns\n",
    "### Closed patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given a list of all frequent sequences and their counts, compute the set of closed frequent sequence (as a list)\n",
    "This is only a very simplistic (naive) implementation for demonstration purposes!\n",
    "\"\"\"\n",
    "def filterClosed(result):\n",
    "    for supersequence, countSeq in copy.deepcopy(result):\n",
    "        for subsequence, countSubSeq in copy.deepcopy(result):\n",
    "            if isSubsequence(supersequence, subsequence) and (countSeq == countSubSeq) and subsequence != supersequence:\n",
    "                result.remove((subsequence, countSubSeq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([['ï¸']], 206),\n",
       " ([['ï¸', 'ðŸ˜Ž']], 128),\n",
       " ([['ðŸ¤', 'ðŸ¦', 'ðŸ˜Ž', 'ðŸ¤ ']], 108),\n",
       " ([['ðŸ¤', 'ðŸ˜Ž', 'ðŸ¤ ']], 120),\n",
       " ([['ðŸ¤', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']], 106),\n",
       " ([['ðŸ¦', 'ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¤ ']], 131),\n",
       " ([['ðŸ¦', 'ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']], 117),\n",
       " ([['ðŸ¦', 'ðŸ˜Ž', 'ðŸ¤ ']], 178),\n",
       " ([['ðŸ¦', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']], 164),\n",
       " ([['ðŸ”¥']], 197),\n",
       " ([['ðŸ”¥', 'ðŸ˜Ž']], 163),\n",
       " ([['ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¤ ']], 161),\n",
       " ([['ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']], 135),\n",
       " ([['ðŸ”¥', 'ðŸ¤ ']], 187),\n",
       " ([['ðŸ˜']], 101),\n",
       " ([['ðŸ˜Ž']], 1000),\n",
       " ([['ðŸ˜Ž', 'ðŸ¤ ']], 645),\n",
       " ([['ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']], 209),\n",
       " ([['ðŸ˜Ž', 'ðŸ¥°']], 211),\n",
       " ([['ðŸ˜Ž'], ['ðŸ¤ ']], 168),\n",
       " ([['ðŸ˜˜']], 110),\n",
       " ([['ðŸ¤—']], 102),\n",
       " ([['ðŸ¤ ']], 1000),\n",
       " ([['ðŸ¤ ', 'ðŸ¥°']], 213),\n",
       " ([['ðŸ¤ '], ['ðŸ˜Ž']], 230),\n",
       " ([['ðŸ¥°']], 233)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = prefixSpan(dataset, 100)\n",
    "filterClosed(result)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximal sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given a list of all frequent sequences and their counts, compute the set of maximal frequent sequence (as a list)\n",
    "This is only a very naive implementation for demonstration purposes!\n",
    "\"\"\"\n",
    "def filterMaximal(result):\n",
    "    for supersequence, countSeq in copy.deepcopy(result):\n",
    "        for subsequence, countSubSeq in copy.deepcopy(result):\n",
    "            if isSubsequence (supersequence, subsequence) and subsequence != supersequence:\n",
    "                result.remove((subsequence, countSubSeq)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([['ï¸', 'ðŸ˜Ž']], 128),\n",
       " ([['ðŸ¤', 'ðŸ¦', 'ðŸ˜Ž', 'ðŸ¤ ']], 108),\n",
       " ([['ðŸ¤', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']], 106),\n",
       " ([['ðŸ¦', 'ðŸ”¥', 'ðŸ˜Ž', 'ðŸ¤ ', 'ðŸ¥°']], 117),\n",
       " ([['ðŸ˜']], 101),\n",
       " ([['ðŸ˜Ž'], ['ðŸ¤ ']], 168),\n",
       " ([['ðŸ˜˜']], 110),\n",
       " ([['ðŸ¤—']], 102),\n",
       " ([['ðŸ¤ '], ['ðŸ˜Ž']], 230)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = prefixSpan (dataset, 100)\n",
    "filterMaximal(result)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
